{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruv1603/voice_GPT/blob/main/voice_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition pydub\n",
        "!apt-get install ffmpeg\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld3DmuEYbOSQ",
        "outputId": "4a01c48d-cc71-402e-dde8-178fd1ef8fd6"
      },
      "id": "Ld3DmuEYbOSQ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.11.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Google Colab Microphone Input Integration"
      ],
      "metadata": {
        "id": "VKE-i2rTaZ15"
      },
      "id": "VKE-i2rTaZ15"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode"
      ],
      "metadata": {
        "id": "xjwY4FBFbYWa"
      },
      "id": "xjwY4FBFbYWa",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lpiZZAL-S8PM"
      },
      "id": "lpiZZAL-S8PM",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record(sec=3):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "audio_file_path = record(sec=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "V565H50saRFX",
        "outputId": "db657f52-1812-4e23-b877-59650e60fcb8"
      },
      "id": "V565H50saRFX",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Voice and GPT"
      ],
      "metadata": {
        "id": "hTl8pezbbQ7D"
      },
      "id": "hTl8pezbbQ7D"
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import display, HTML\n",
        "# import openai\n",
        "# import os\n",
        "# from google.colab import output\n",
        "# from transformers import pipeline\n",
        "# import ipywidgets as widgets\n",
        "# from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "4R8GvX6-db6M"
      },
      "id": "4R8GvX6-db6M",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "from transformers import pipeline\n",
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "JSP1LXkMbWP1"
      },
      "id": "JSP1LXkMbWP1",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables\n",
        "recognized_text = None"
      ],
      "metadata": {
        "id": "GsbrNQLLbgDO"
      },
      "id": "GsbrNQLLbgDO",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the text generation pipeline\n",
        "generator = pipeline('text-generation', model='gpt2')"
      ],
      "metadata": {
        "id": "wlzeHHJrhCJc"
      },
      "id": "wlzeHHJrhCJc",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_recognized_text(text):\n",
        "    global recognized_text\n",
        "    recognized_text = text\n",
        "    output_text.value = f\"Recognized Text: {recognized_text}\""
      ],
      "metadata": {
        "id": "YZWy90k4bhZ0"
      },
      "id": "YZWy90k4bhZ0",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt):\n",
        "    response = generator(prompt, max_length=100, num_return_sequences=1)\n",
        "    return response[0]['generated_text']"
      ],
      "metadata": {
        "id": "0mwbSZ82bjq2"
      },
      "id": "0mwbSZ82bjq2",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_button_clicked(b):\n",
        "    global recognized_text\n",
        "    # Use recognized text if available; otherwise, use text from the input box\n",
        "    prompt = recognized_text if recognized_text else input_text.value.strip()\n",
        "\n",
        "    if prompt:\n",
        "        response = generate_response(prompt)\n",
        "        ai_response_output.value = f\"AI Response: {response}\"\n",
        "    else:\n",
        "        ai_response_output.value = \"No text recognized or provided.\""
      ],
      "metadata": {
        "id": "99IFPXEBhJcf"
      },
      "id": "99IFPXEBhJcf",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create HTML and JavaScript for voice recording\n",
        "html_code = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Voice to Text Converter</title>\n",
        "    <script>\n",
        "        let recognition;\n",
        "        let isRecording = false;\n",
        "\n",
        "        function startRecognition() {\n",
        "            if (!('webkitSpeechRecognition' in window)) {\n",
        "                alert(\"Sorry, your browser doesn't support speech recognition.\");\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            recognition = new webkitSpeechRecognition();\n",
        "            recognition.continuous = false;\n",
        "            recognition.interimResults = false;\n",
        "\n",
        "            recognition.onstart = function() {\n",
        "                document.getElementById(\"status\").innerHTML = \"Recording...\";\n",
        "                isRecording = true;\n",
        "            };\n",
        "\n",
        "            recognition.onresult = function(event) {\n",
        "                const transcript = event.results[0][0].transcript;\n",
        "                document.getElementById(\"output\").innerHTML = transcript;\n",
        "                isRecording = false;\n",
        "                document.getElementById(\"status\").innerHTML = \"Recording stopped.\";\n",
        "                google.colab.kernel.invokeFunction('handle_recognized_text', [transcript], {}); // Send the text to Python\n",
        "            };\n",
        "\n",
        "            recognition.onerror = function(event) {\n",
        "                alert(\"Error occurred in recognition: \" + event.error);\n",
        "                isRecording = false;\n",
        "            };\n",
        "\n",
        "            recognition.onend = function() {\n",
        "                if (isRecording) {\n",
        "                    recognition.start(); // Restart recognition if it ends unexpectedly\n",
        "                }\n",
        "            };\n",
        "\n",
        "            recognition.start();\n",
        "        }\n",
        "\n",
        "        function stopRecognition() {\n",
        "            if (recognition) {\n",
        "                recognition.stop();\n",
        "                document.getElementById(\"status\").innerHTML = \"Recording stopped.\";\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Voice to Text Converter</h1>\n",
        "    <button onclick=\"startRecognition()\" style=\"padding: 10px; background-color: #4CAF50; color: white; border: none; border-radius: 5px;\">Start Recording</button>\n",
        "    <button onclick=\"stopRecognition()\" style=\"padding: 10px; background-color: #f44336; color: white; border: none; border-radius: 5px;\">Stop Recording</button>\n",
        "    <p id=\"status\" style=\"font-weight: bold;\"></p>\n",
        "    <h2>Recognized Text:</h2>\n",
        "    <p id=\"output\" style=\"border: 1px solid #ccc; padding: 10px; min-height: 50px; background-color: #f9f9f9;\"></p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OG4_hfTbboXD"
      },
      "id": "OG4_hfTbboXD",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create widgets\n",
        "output_text = widgets.Textarea(value=\"\", description=\"Recognized Text:\", layout=widgets.Layout(width='100%', height='80px'))\n",
        "ai_response_output = widgets.Textarea(value=\"\", description=\"AI Response:\", layout=widgets.Layout(width='100%', height='120px'))\n",
        "input_text = widgets.Textarea(placeholder='Type your text here...', description='Input Text:', layout=widgets.Layout(width='100%', height='80px'))"
      ],
      "metadata": {
        "id": "GqouuVPibsS5"
      },
      "id": "GqouuVPibsS5",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create button for generating response\n",
        "generate_response_button = widgets.Button(description=\"Generate Response\", button_style='primary', layout=widgets.Layout(width='30%', height='40px'))\n",
        "generate_response_button.on_click(generate_response_button_clicked)"
      ],
      "metadata": {
        "id": "wVCO2JDvbuoE"
      },
      "id": "wVCO2JDvbuoE",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a box layout for the input fields and buttons\n",
        "input_section = widgets.VBox([input_text, output_text, generate_response_button, ai_response_output], layout=widgets.Layout(padding='10px', border='1px solid #ddd', border_radius='10px', width='80%', margin='0 auto'))"
      ],
      "metadata": {
        "id": "IVRt63ekhUxk"
      },
      "id": "IVRt63ekhUxk",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the HTML for voice recognition\n",
        "display(HTML(html_code))\n",
        "\n",
        "# Register the Python function as a callback\n",
        "output.register_callback('handle_recognized_text', handle_recognized_text)\n",
        "\n",
        "# Display the input section with the widgets\n",
        "display(input_section)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705,
          "referenced_widgets": [
            "ade85a65fd574608912f6c65a48cdd97",
            "5cf78d3710ca47408dd4de68a3da73fb",
            "ac1fe0dd223848e9b4e3d57ea891d0e8",
            "526d9aeb002d42dcbc86ee5893da2111",
            "02a37cbcbda743bd8c906f85c9bf8ee3",
            "7a416cbec4794ac9a8a3ae22fe7357cd",
            "4cf87ea55ad94d799835d9c6696bc815",
            "b18157b9d4984e798c7fed756104cf15",
            "9135c9ed383544b5998ecd9c456e6992",
            "01ac20147a5e49e78d9f278f563c8cd9",
            "ad805942ba2741e3a8a32041513a343f",
            "05492a3e4c024b6faa1fc73fc2098969",
            "54e4b36fa314405dbf1d597077074d91",
            "a7b5d05c053c42348dbc9ae9f67d169d"
          ]
        },
        "id": "BQCs-vvEbxIk",
        "outputId": "19cc88d5-8b9d-48dd-cc4f-50990261e68e"
      },
      "id": "BQCs-vvEbxIk",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "    <title>Voice to Text Converter</title>\n",
              "    <script>\n",
              "        let recognition;\n",
              "        let isRecording = false;\n",
              "\n",
              "        function startRecognition() {\n",
              "            if (!('webkitSpeechRecognition' in window)) {\n",
              "                alert(\"Sorry, your browser doesn't support speech recognition.\");\n",
              "                return;\n",
              "            }\n",
              "\n",
              "            recognition = new webkitSpeechRecognition();\n",
              "            recognition.continuous = false;\n",
              "            recognition.interimResults = false;\n",
              "\n",
              "            recognition.onstart = function() {\n",
              "                document.getElementById(\"status\").innerHTML = \"Recording...\";\n",
              "                isRecording = true;\n",
              "            };\n",
              "\n",
              "            recognition.onresult = function(event) {\n",
              "                const transcript = event.results[0][0].transcript;\n",
              "                document.getElementById(\"output\").innerHTML = transcript;\n",
              "                isRecording = false;\n",
              "                document.getElementById(\"status\").innerHTML = \"Recording stopped.\";\n",
              "                google.colab.kernel.invokeFunction('handle_recognized_text', [transcript], {}); // Send the text to Python\n",
              "            };\n",
              "\n",
              "            recognition.onerror = function(event) {\n",
              "                alert(\"Error occurred in recognition: \" + event.error);\n",
              "                isRecording = false;\n",
              "            };\n",
              "\n",
              "            recognition.onend = function() {\n",
              "                if (isRecording) {\n",
              "                    recognition.start(); // Restart recognition if it ends unexpectedly\n",
              "                }\n",
              "            };\n",
              "\n",
              "            recognition.start();\n",
              "        }\n",
              "\n",
              "        function stopRecognition() {\n",
              "            if (recognition) {\n",
              "                recognition.stop();\n",
              "                document.getElementById(\"status\").innerHTML = \"Recording stopped.\";\n",
              "            }\n",
              "        }\n",
              "    </script>\n",
              "</head>\n",
              "<body>\n",
              "    <h1>Voice to Text Converter</h1>\n",
              "    <button onclick=\"startRecognition()\" style=\"padding: 10px; background-color: #4CAF50; color: white; border: none; border-radius: 5px;\">Start Recording</button>\n",
              "    <button onclick=\"stopRecognition()\" style=\"padding: 10px; background-color: #f44336; color: white; border: none; border-radius: 5px;\">Stop Recording</button>\n",
              "    <p id=\"status\" style=\"font-weight: bold;\"></p>\n",
              "    <h2>Recognized Text:</h2>\n",
              "    <p id=\"output\" style=\"border: 1px solid #ccc; padding: 10px; min-height: 50px; background-color: #f9f9f9;\"></p>\n",
              "</body>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Textarea(value='', description='Input Text:', layout=Layout(height='80px', width='100%'), place…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ade85a65fd574608912f6c65a48cdd97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-9PEEVubb-jy"
      },
      "id": "-9PEEVubb-jy",
      "execution_count": 47,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ade85a65fd574608912f6c65a48cdd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cf78d3710ca47408dd4de68a3da73fb",
              "IPY_MODEL_ac1fe0dd223848e9b4e3d57ea891d0e8",
              "IPY_MODEL_526d9aeb002d42dcbc86ee5893da2111",
              "IPY_MODEL_02a37cbcbda743bd8c906f85c9bf8ee3"
            ],
            "layout": "IPY_MODEL_7a416cbec4794ac9a8a3ae22fe7357cd"
          }
        },
        "5cf78d3710ca47408dd4de68a3da73fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Input Text:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4cf87ea55ad94d799835d9c6696bc815",
            "placeholder": "Type your text here...",
            "rows": null,
            "style": "IPY_MODEL_b18157b9d4984e798c7fed756104cf15",
            "value": "Who is Narendra Modi"
          }
        },
        "ac1fe0dd223848e9b4e3d57ea891d0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Recognized Text:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9135c9ed383544b5998ecd9c456e6992",
            "placeholder": "​",
            "rows": null,
            "style": "IPY_MODEL_01ac20147a5e49e78d9f278f563c8cd9",
            "value": "Recognized Text: Hello, can you please tell me the update about new AI?"
          }
        },
        "526d9aeb002d42dcbc86ee5893da2111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Generate Response",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ad805942ba2741e3a8a32041513a343f",
            "style": "IPY_MODEL_05492a3e4c024b6faa1fc73fc2098969",
            "tooltip": ""
          }
        },
        "02a37cbcbda743bd8c906f85c9bf8ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "AI Response:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_54e4b36fa314405dbf1d597077074d91",
            "placeholder": "​",
            "rows": null,
            "style": "IPY_MODEL_a7b5d05c053c42348dbc9ae9f67d169d",
            "value": "AI Response: Hello, can you please tell me the update about new AI? I'm really surprised that the AI has been in such a bad state. It seems like we're seeing our first AI, but I don't know how. Anyway, this should show us how AI's got changed when we start getting work done. I mean, the original AI, you know, was pretty good. The current AI is pretty bad at it and it's not doing very well, but they're doing better. Well"
          }
        },
        "7a416cbec4794ac9a8a3ae22fe7357cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid #ddd",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "0 auto",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "10px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "4cf87ea55ad94d799835d9c6696bc815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "80px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b18157b9d4984e798c7fed756104cf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9135c9ed383544b5998ecd9c456e6992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "80px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "01ac20147a5e49e78d9f278f563c8cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad805942ba2741e3a8a32041513a343f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "40px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "30%"
          }
        },
        "05492a3e4c024b6faa1fc73fc2098969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "54e4b36fa314405dbf1d597077074d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "120px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a7b5d05c053c42348dbc9ae9f67d169d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}